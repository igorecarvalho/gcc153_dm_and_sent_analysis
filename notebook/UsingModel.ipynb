{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>news</th>\n",
       "      <th>polarity_new</th>\n",
       "      <th>news_keywords</th>\n",
       "      <th>tweets</th>\n",
       "      <th>normalized_tweets</th>\n",
       "      <th>polarity_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>[[PF emite certidão à Justiça para dizer que L...</td>\n",
       "      <td>None</td>\n",
       "      <td>(lava, jato)</td>\n",
       "      <td>1399    Lava Jato cobra multa de R$ 5 milhões ...</td>\n",
       "      <td>1399    [lava, jato, cobra, multa, de, r, 5, m...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>[[Para Maia, derrota em abono não significa pe...</td>\n",
       "      <td>None</td>\n",
       "      <td>(reforma, previdência)</td>\n",
       "      <td>1398    Economia com reforma da Previdência de...</td>\n",
       "      <td>1398    [economia, com, reforma, da, previdênc...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>[[Flávia Boggio | Acho impossível esconder a i...</td>\n",
       "      <td>None</td>\n",
       "      <td>(pacote, anticrime)</td>\n",
       "      <td>1399    Governo Federal lança campanha publici...</td>\n",
       "      <td>1399    [governo, federal, lança, campanha, pu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>[[Camargo processa ex-executivo por desvio mil...</td>\n",
       "      <td>None</td>\n",
       "      <td>(lava, jato)</td>\n",
       "      <td>1399    # BRASIL: Los fiscales justicieros del...</td>\n",
       "      <td>1399    [brasil, los, fiscales, justicieros, d...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-05</td>\n",
       "      <td>[[Desde janeiro, o jornal tem uma editoria de ...</td>\n",
       "      <td>None</td>\n",
       "      <td>(conselhos, tutelares)</td>\n",
       "      <td>1399    Invasão da Universal ameaça aparelhar ...</td>\n",
       "      <td>1399    [invasão, da, universal, ameaça, apare...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               news polarity_new  \\\n",
       "0  2019-10-01  [[PF emite certidão à Justiça para dizer que L...         None   \n",
       "1  2019-10-02  [[Para Maia, derrota em abono não significa pe...         None   \n",
       "2  2019-10-03  [[Flávia Boggio | Acho impossível esconder a i...         None   \n",
       "3  2019-10-04  [[Camargo processa ex-executivo por desvio mil...         None   \n",
       "4  2019-10-05  [[Desde janeiro, o jornal tem uma editoria de ...         None   \n",
       "\n",
       "            news_keywords                                             tweets  \\\n",
       "0            (lava, jato)  1399    Lava Jato cobra multa de R$ 5 milhões ...   \n",
       "1  (reforma, previdência)  1398    Economia com reforma da Previdência de...   \n",
       "2     (pacote, anticrime)  1399    Governo Federal lança campanha publici...   \n",
       "3            (lava, jato)  1399    # BRASIL: Los fiscales justicieros del...   \n",
       "4  (conselhos, tutelares)  1399    Invasão da Universal ameaça aparelhar ...   \n",
       "\n",
       "                                   normalized_tweets polarity_tweets  \n",
       "0  1399    [lava, jato, cobra, multa, de, r, 5, m...            None  \n",
       "1  1398    [economia, com, reforma, da, previdênc...            None  \n",
       "2  1399    [governo, federal, lança, campanha, pu...            None  \n",
       "3  1399    [brasil, los, fiscales, justicieros, d...            None  \n",
       "4  1399    [invasão, da, universal, ameaça, apare...            None  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depurate_tweets = pd.read_pickle('../data/depurate_tweets.pkl')\n",
    "depurate_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.load('../models/modelo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [stemmer.stem(i) for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f857be27f7bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfreq_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "freq_tweets = vectorizer.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cc8b0071121d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtestes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Transforma os dados de teste em vetores de palavras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfreq_testes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fazendo a classificação com o modelo treinado.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_testes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "#testes = list(itertools.chain.from_iterable(depurate_tweets['news'][13]))\n",
    "testes = depurate_tweets['tweets'][27]\n",
    "testes = [Preprocessing(i) for i in testes]\n",
    "# Transforma os dados de teste em vetores de palavras.\n",
    "freq_testes = vectorizer.transform(testes)\n",
    "# Fazendo a classificação com o modelo treinado.\n",
    "pd.DataFrame(modelo.predict(freq_testes)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades de cada classe\n",
    "print (modelo.classes_)\n",
    "modelo.predict_proba(freq_testes).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depurate_tweets['tweets'][27], modelo.predict(freq_testes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
